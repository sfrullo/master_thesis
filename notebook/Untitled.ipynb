{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# native\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# external\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import xmltodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "os.environ.update({\n",
    "    \"MAHNOB_DIR\" : \"\",\n",
    "    \"EXPORT_DIR_BASE\": \"\"\n",
    "})\n",
    "\n",
    "import emosm\n",
    "from emosm.dataset.mahnob import mahnob\n",
    "from emosm.dataset.mahnob import config\n",
    "from emosm.sm import gazesm, physiosm\n",
    "\n",
    "from emosm.plot import gazeplot\n",
    "\n",
    "import emosm.fe.feature_extractor as fe\n",
    "\n",
    "from emosm.tools import export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOW = time.strftime(\"%y%m%d%H%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing MAHNOB dataset...\n"
     ]
    }
   ],
   "source": [
    "dataset = mahnob.Mahnob()\n",
    "\n",
    "# sessions = dataset.get_session_by_id(10)\n",
    "# sessions = dataset.get_session_by_id([10,160])\n",
    "sessions = dataset.get_sessions_by_mediafile(\"53.avi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit_frame = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_media_info(media, limit_frame=None):\n",
    "    scale_media = config.SCALE_MEDIA\n",
    "    display_size = media.get_size(scaled=scale_media)\n",
    "    media_fps = media.metadata[\"fps\"]\n",
    "    media_frames_gen = media.get_frames(limit_frame=limit_frame, scale=scale_media, bw=True)\n",
    "    return media_frames_gen, media_fps, display_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_gaze_scanpath(sessions, limit_frame, destination):\n",
    "\n",
    "    ## EXPORT GAZE SCANPATH FOR EACH SUBJECT\n",
    "\n",
    "    for sid, session in sessions.items():\n",
    "\n",
    "        media = session.get_media()\n",
    "        media_frames_gen, media_fps, display_size = get_media_info(media=media, limit_frame=limit_frame)\n",
    "\n",
    "        gaze_data = mahnob.Mahnob.collect_gaze_data(sessions={sid:session}, mapped=True)\n",
    "        scanpath_generator = gazeplot.gaze_scanpath_plot_generator(gaze_data=gaze_data, limit_frame=limit_frame, fps=media_fps, display_size=display_size)\n",
    "\n",
    "        if destination in [\"video\"]:\n",
    "\n",
    "            filename = config.VIDEO_EXPORT_DIR_BASE + '/scanpath_{}_{}_{}.mp4'.format(sid, media.get_name(), NOW)\n",
    "            export.toVideoSimple(data_frame_gen=scanpath_generator, media_frames_gen=media_frames_gen, filename=filename, fps=media_fps)\n",
    "\n",
    "        elif destination in [\"return\"]:\n",
    "\n",
    "            yield scanpath_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_gaze_sm(sessions, limit_frame, per_subject, destination):\n",
    "    ## COMPUTE GAZE SALIENCY MAP FOR EACH SUBJECT\n",
    "\n",
    "    if per_subject is False:\n",
    "\n",
    "        for sid, session in sessions.items():\n",
    "            media = session.get_media()\n",
    "            break\n",
    "\n",
    "        media_frames_gen, media_fps, display_size = get_media_info(media=media, limit_frame=limit_frame)\n",
    "\n",
    "        gaze_data = mahnob.Mahnob.collect_gaze_data(sessions=sessions, mapped=True, preprocess=True)\n",
    "        gaze_sm_gen = compute_gaze_sm(gaze_data=gaze_data, display_size=display_size, limit_frame=limit_frame)\n",
    "\n",
    "        if destination in [\"video\"]:\n",
    "\n",
    "            filename = config.VIDEO_EXPORT_DIR_BASE + '/gazesm_{}_{}.mp4'.format(media.get_name(), NOW)\n",
    "            export.toVideo(sm_frame_gen=gaze_sm_gen, media_frames_gen=media_frames_gen, filename=filename, fps=media_fps)\n",
    "\n",
    "        elif destination in [\"return\"]:\n",
    "\n",
    "            return gaze_sm_gen\n",
    "\n",
    "    else:\n",
    "\n",
    "        for sid, session in sessions.items():\n",
    "\n",
    "            media = session.get_media()\n",
    "            media_frames_gen, media_fps, display_size = get_media_info(media=media, limit_frame=limit_frame)\n",
    "\n",
    "            gaze_data = mahnob.Mahnob.collect_gaze_data(sessions={sid:session}, mapped=True)\n",
    "            gaze_sm_gen = compute_gaze_sm(gaze_data=gaze_data, display_size=display_size, limit_frame=limit_frame)\n",
    "\n",
    "            if destination in [\"video\"]:\n",
    "\n",
    "                filename = config.VIDEO_EXPORT_DIR_BASE + '/gazesm_{}_{}_{}.mp4'.format(sid, media.get_name(), NOW)\n",
    "                export.toVideo(sm_frame_gen=gaze_sm_gen, media_frames_gen=media_frames_gen, filename=filename, fps=media_fps)\n",
    "\n",
    "            elif destination in [\"return\"]:\n",
    "\n",
    "                return gaze_sm_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_physiological_signals_in_sessions(sessions, signals):\n",
    "\n",
    "    ## LOAD AND SHOW PHYSIOLOGICAL DATA FOR GIVEN SESSSION\n",
    "\n",
    "    for sid, session in sessions.items():\n",
    "        physio_data = session.get_physiological_data(signals=signals)\n",
    "        for sigtype, data in physio_data.items():\n",
    "            data.get_data(preprocess=True, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_separated_physiological_saliency_map(sessions, media, signals, psyco_construct_list, attribute_list, limit_frame, destination):\n",
    "\n",
    "    ## COMPUTE AND EXPORT SEPARATED PSYCOPHYSIOLOGICAL SALIENCY MAP FOR GIVEN SESSSION AND GIVEN SIGNALS\n",
    "\n",
    "    media_frames_gen, media_fps, display_size = get_media_info(media=media, limit_frame=limit_frame)\n",
    "\n",
    "    gaze_data = mahnob.Mahnob.collect_gaze_data(sessions=sessions, mapped=True)\n",
    "    physio_data = mahnob.Mahnob.collect_physiological_data(sessions=sessions, signals=signals)\n",
    "    for sigtype, data in physio_data.items():\n",
    "        for psyco_construct in psyco_construct_list:\n",
    "            for attribute in attribute_list:\n",
    "                opts = {\n",
    "                    \"sigtype\" : sigtype,\n",
    "                    \"attribute\" : attribute,\n",
    "                    \"psyco_construct\" : psyco_construct,\n",
    "                    \"fps\" : media_fps\n",
    "                }\n",
    "\n",
    "                features = fe.extract_physiological_feature(data=data, opts=opts)\n",
    "                psm = physiosm.PhysioSaliencyMap(physio=features, gaze=gaze_data, media=media)\n",
    "                physio_sm_gen = psm.compute_saliency_map(limit_frame=limit_frame, display_size=display_size)\n",
    "\n",
    "                if destination in [\"video\"]:\n",
    "\n",
    "                    filename = config.VIDEO_EXPORT_DIR_BASE + '/physm_{}_{}_{}_{}.mp4'.format(psyco_construct, attribute, sigtype, NOW)\n",
    "                    export.toVideo(sm_frame_gen=physio_sm_gen, media_frames_gen=media_frames_gen, filename=filename, fps=media_fps)\n",
    "\n",
    "                elif destination in [\"return\"]:\n",
    "\n",
    "                    yield physio_sm_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_composed_physiological_saliency_map(sessions, media, signals, psyco_construct, attribute, limit_frame, destination):\n",
    "\n",
    "    ## COMPUTE AND EXPORT INTEGRATED PSYCOPHYSIOLOGICAL SALIENCY MAP FOR GIVEN SESSSION AND GIVEN SIGNALS\n",
    "\n",
    "    media_frames_gen, media_fps, display_size = get_media_info(media=media, limit_frame=limit_frame)\n",
    "\n",
    "    physio_sm_list = []\n",
    "\n",
    "    gaze_data = mahnob.Mahnob.collect_gaze_data(sessions=sessions, mapped=True)\n",
    "    physio_data = mahnob.Mahnob.collect_physiological_data(sessions=sessions, signals=signals)\n",
    "\n",
    "    max_sample = min([ d.stop - d.start for k,data in physio_data.items() for d in data ])\n",
    "\n",
    "    for sigtype, data in physio_data.items():\n",
    "        opts = {\n",
    "            \"sigtype\" : sigtype,\n",
    "            \"attribute\" : attribute,\n",
    "            \"psyco_construct\" : psyco_construct,\n",
    "            \"fps\" : media_fps,\n",
    "            \"max_sample\" : max_sample,\n",
    "        }\n",
    "\n",
    "        features = fe.extract_physiological_feature(data=data, opts=opts)\n",
    "        psm = physiosm.PhysioSaliencyMap(physio=features, gaze=gaze_data, media=media)\n",
    "        physio_sm_gen = psm.compute_saliency_map(limit_frame=limit_frame, display_size=display_size)\n",
    "        physio_sm_list.append(physio_sm_gen)\n",
    "\n",
    "    # create generator to integrate framed physiological data\n",
    "    composed_sm = physiosm.physioSaliencyMapComposer(physio_sm_list)\n",
    "\n",
    "    if destination in [\"video\"]:\n",
    "\n",
    "        signals = \"_\".join(signals)\n",
    "        filename = config.VIDEO_EXPORT_DIR_BASE + '/physm_composed_{}_{}_{}_{}.mp4'.format(psyco_construct, attribute, signals, NOW)\n",
    "        export.toVideo(sm_frame_gen=composed_sm, media_frames_gen=media_frames_gen, filename=filename, fps=media_fps)\n",
    "\n",
    "    elif destination in [\"return\"]:\n",
    "\n",
    "        return composed_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_session_data_to_file(sessions, limit_frame):\n",
    "\n",
    "    print \"export_session_data_to_file\"\n",
    "\n",
    "    for sid, session in sessions.items():\n",
    "\n",
    "        session_info = session.get_session_info()\n",
    "\n",
    "        gaze_data = session.get_gaze_data()\n",
    "\n",
    "        coordinates_raw = gaze_data.get_gaze_coordinates(mapped=True)\n",
    "        coordinates = gaze_data.get_gaze_coordinates(mapped=True, preprocess=True)\n",
    "\n",
    "        fixations_raw = gaze_data.get_fixations_data()\n",
    "        fixations = gaze_data.get_fixations_data(preprocess=True)\n",
    "\n",
    "        data = {\n",
    "            \"session_info\" : session_info,\n",
    "            \"coordinates_raw\" : coordinates_raw,\n",
    "            \"coordinates\" : coordinates,\n",
    "            \"fixations_raw\" : fixations_raw,\n",
    "            \"fixations\" : fixations,\n",
    "        }\n",
    "\n",
    "        filename = config.DATA_EXPORT_DIR_BASE + \"/gaze_data_{}_{}.npz\".format(sid, NOW)\n",
    "        export.toBinaryFile(data=data, filename=filename, compressed=True)\n",
    "\n",
    "        del gaze_data\n",
    "        del data\n",
    "\n",
    "        physio_data = session.get_physiological_data(signals=[\"ECG\",\"EDA\",\"Resp\",\"SKT\"])\n",
    "\n",
    "        if physio_data:\n",
    "            signals = {}\n",
    "            for signal, signal_class in physio_data.items():\n",
    "                signals[signal.lower() + \"_raw\"] = signal_class.get_data()\n",
    "                signals[signal.lower()] = signal_class.get_data(preprocess=True)\n",
    "\n",
    "        data = dict(\n",
    "            session_info=session_info,\n",
    "            **signals\n",
    "        )\n",
    "\n",
    "        filename = config.DATA_EXPORT_DIR_BASE + \"/physio_data_{}_{}.npz\".format(sid, NOW)\n",
    "        export.toBinaryFile(data=data, filename=filename, compressed=True)\n",
    "\n",
    "        del session_info\n",
    "        del physio_data\n",
    "        del signals\n",
    "        del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## EXPORT TO BINARY FILE\n",
    "##\n",
    "\n",
    "export_session_data_to_file(sessions=sessions, limit_frame=limit_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## EXPORT GAZE SCANPATH FOR EACH SUBJECT\n",
    "##\n",
    "\n",
    "export_gaze_scanpath(sessions=sessions, limit_frame=limit_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## COMPUTE GAZE SALIENCY MAP FOR EACH SUBJECT\n",
    "##\n",
    "\n",
    "export_gaze_sm(sessions=sessions, limit_frame=limit_frame, per_subject=True, destination=\"video\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## COMPUTE GAZE SALIENCY MAP USING ALL SUBJECTS\n",
    "##\n",
    "\n",
    "export_gaze_sm(sessions=sessions, limit_frame=limit_frame, per_subject=False, destination=\"video\")\n",
    "\n",
    "# sm = export_gaze_sm(sessions=sessions, limit_frame=limit_frame, per_subject=False, destination=\"return\")\n",
    "# filename = config.DATA_EXPORT_DIR_BASE + \"/gaze_sm_{}.npz\".format(NOW)\n",
    "# data = {\n",
    "#     \"gaze_sm\" : sm\n",
    "# }\n",
    "# export.toBinaryFile(data=data, filename=filename, compressed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## LOAD AND SHOW PHYSIOLOGICAL DATA FOR GIVEN SESSSION\n",
    "##\n",
    "\n",
    "signals=[\"SKT\"]\n",
    "show_physiological_signals_in_sessions(sessions=sessions, signals=signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## EXPORT PHYSIOLOGICAL SALIENCY MAP\n",
    "##\n",
    "\n",
    "for sid, session in sessions.items():\n",
    "    media = session.get_media()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## COMPUTE AND EXPORT SEPARATED PSYCOPHYSIOLOGICAL SALIENCY MAP FOR GIVEN SESSSION AND GIVEN SIGNALS\n",
    "##\n",
    "\n",
    "signals=[\"EDA\"]\n",
    "psyco_construct=[\"valence\"]\n",
    "attribute=[\"mean\"]\n",
    "export_separated_physiological_saliency_map(sessions=sessions, \\\n",
    "                                            media=media, \\\n",
    "                                            signals=signals, \\\n",
    "                                            psyco_construct_list=psyco_construct, \\\n",
    "                                            attribute_list=attribute, \\\n",
    "                                            limit_frame=limit_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[set(['ECG']), set(['EDA']), set(['Resp']), set(['SKT']), set(['ECG', 'EDA']), set(['ECG', 'Resp']), set(['ECG', 'SKT']), set(['Resp', 'EDA']), set(['SKT', 'EDA']), set(['SKT', 'Resp']), set(['ECG', 'Resp', 'EDA']), set(['ECG', 'SKT', 'EDA']), set(['ECG', 'SKT', 'Resp']), set(['SKT', 'Resp', 'EDA']), set(['ECG', 'SKT', 'Resp', 'EDA'])]\n",
      "Load gaze data for sessions #10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python2/lib/python2.7/site-packages/scipy/signal/signaltools.py:2223: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  Y[sl] = X[sl]\n",
      "/opt/conda/envs/python2/lib/python2.7/site-packages/scipy/signal/signaltools.py:2225: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  Y[sl] = X[sl]\n",
      "/opt/conda/envs/python2/lib/python2.7/site-packages/scipy/signal/signaltools.py:2230: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  Y[sl] += X[sl]  # add the component of X at N/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load gaze data for sessions #160\n",
      "Load gaze data for sessions #426\n",
      "Load gaze data for sessions #546\n",
      "Load gaze data for sessions #814\n",
      "Load gaze data for sessions #948\n",
      "Load gaze data for sessions #1206\n",
      "Load gaze data for sessions #1588\n",
      "Load gaze data for sessions #1698\n",
      "Load gaze data for sessions #1956\n",
      "Load gaze data for sessions #2090\n",
      "Load gaze data for sessions #2224\n",
      "Load gaze data for sessions #2358\n",
      "Load gaze data for sessions #2492\n",
      "Load gaze data for sessions #2626\n",
      "Load gaze data for sessions #2760\n",
      "Load gaze data for sessions #2894\n",
      "Load gaze data for sessions #3028\n",
      "Load gaze data for sessions #3412\n",
      "Load gaze data for sessions #3538\n",
      "Load gaze data for sessions #3664\n",
      "Load gaze data for sessions #3790\n",
      "Load physiological data for sessions #10\n",
      "Load data from /home/jovyan/Dataset/Mahnob/data/Sessions/10/Part_1_S_Trial5_emotion.bdf..\n",
      "Load ECG data..\n",
      "Load physiological data for sessions #160\n",
      "Load data from /home/jovyan/Dataset/Mahnob/data/Sessions/160/Part_2_S_Trial15_emotion.bdf..\n",
      "Load ECG data..\n",
      "Load physiological data for sessions #426\n",
      "Load data from /home/jovyan/Dataset/Mahnob/data/Sessions/426/Part_4_S_Trial18_emotion.bdf..\n",
      "Load ECG data..\n",
      "Load physiological data for sessions #546\n",
      "Load data from /home/jovyan/Dataset/Mahnob/data/Sessions/546/Part_5_S_Trial13_emotion.bdf..\n",
      "Load ECG data..\n",
      "Load physiological data for sessions #814\n",
      "Load data from /home/jovyan/Dataset/Mahnob/data/Sessions/814/Part_7_S_Trial17_emotion.bdf..\n",
      "Load ECG data..\n",
      "Load physiological data for sessions #948\n",
      "Load data from /home/jovyan/Dataset/Mahnob/data/Sessions/948/Part_8_S_Trial19_emotion.bdf..\n",
      "Load ECG data..\n",
      "Load physiological data for sessions #1206\n",
      "Load data from /home/jovyan/Dataset/Mahnob/data/Sessions/1206/Part_10_S_Trial18_emotion.bdf..\n",
      "Load ECG data..\n",
      "Load physiological data for sessions #1588\n",
      "Load data from /home/jovyan/Dataset/Mahnob/data/Sessions/1588/Part_13_S_Trial14_emotion.bdf..\n",
      "Load ECG data..\n",
      "Load physiological data for sessions #1698\n",
      "Load data from /home/jovyan/Dataset/Mahnob/data/Sessions/1698/Part_14_S_Trial4_emotion.bdf..\n",
      "Load ECG data..\n",
      "Load physiological data for sessions #1956\n",
      "Load data from /home/jovyan/Dataset/Mahnob/data/Sessions/1956/Part_16_S_Trial3_emotion.bdf..\n",
      "Load ECG data..\n",
      "Load physiological data for sessions #2090\n",
      "Load data from /home/jovyan/Dataset/Mahnob/data/Sessions/2090/Part_17_S_Trial5_emotion.bdf..\n",
      "Load ECG data..\n",
      "Load physiological data for sessions #2224\n",
      "Load data from /home/jovyan/Dataset/Mahnob/data/Sessions/2224/Part_18_S_Trial7_emotion.bdf..\n",
      "Load ECG data..\n",
      "Load physiological data for sessions #2358\n",
      "Load data from /home/jovyan/Dataset/Mahnob/data/Sessions/2358/Part_19_S_Trial9_emotion.bdf..\n",
      "Load ECG data..\n",
      "Load physiological data for sessions #2492\n",
      "Load data from /home/jovyan/Dataset/Mahnob/data/Sessions/2492/Part_20_S_Trial11_emotion.bdf..\n",
      "Load ECG data..\n",
      "Load physiological data for sessions #2626\n",
      "Load data from /home/jovyan/Dataset/Mahnob/data/Sessions/2626/Part_21_S_Trial13_emotion.bdf..\n",
      "Load ECG data..\n",
      "Load physiological data for sessions #2760\n",
      "Load data from /home/jovyan/Dataset/Mahnob/data/Sessions/2760/Part_22_S_Trial15_emotion.bdf..\n",
      "Load ECG data..\n",
      "Load physiological data for sessions #2894\n",
      "Load data from /home/jovyan/Dataset/Mahnob/data/Sessions/2894/Part_23_S_Trial17_emotion.bdf..\n",
      "Load ECG data..\n",
      "Load physiological data for sessions #3028\n",
      "Load data from /home/jovyan/Dataset/Mahnob/data/Sessions/3028/Part_24_S_Trial19_emotion.bdf..\n",
      "Load ECG data..\n",
      "Load physiological data for sessions #3412\n",
      "Load data from /home/jovyan/Dataset/Mahnob/data/Sessions/3412/Part_27_S_Trial16_emotion.bdf..\n",
      "Load ECG data..\n",
      "Load physiological data for sessions #3538\n",
      "Load data from /home/jovyan/Dataset/Mahnob/data/Sessions/3538/Part_28_S_Trial14_emotion.bdf..\n",
      "Load ECG data..\n",
      "Load physiological data for sessions #3664\n",
      "Load data from /home/jovyan/Dataset/Mahnob/data/Sessions/3664/Part_29_S_Trial12_emotion.bdf..\n",
      "Load ECG data..\n",
      "Load physiological data for sessions #3790\n",
      "Load data from /home/jovyan/Dataset/Mahnob/data/Sessions/3790/Part_30_S_Trial10_emotion.bdf..\n",
      "Load ECG data..\n",
      "prepocess data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python2/lib/python2.7/site-packages/scipy/signal/_arraytools.py:45: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  b = a[a_slice]\n",
      "/opt/conda/envs/python2/lib/python2.7/site-packages/scipy/signal/signaltools.py:1341: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  out_full[ind] += zi\n",
      "/opt/conda/envs/python2/lib/python2.7/site-packages/scipy/signal/signaltools.py:1344: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  out = out_full[ind]\n",
      "/opt/conda/envs/python2/lib/python2.7/site-packages/scipy/signal/signaltools.py:1350: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  zf = out_full[ind]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepocess data ...\n",
      "prepocess data ...\n",
      "prepocess data ...\n",
      "prepocess data ...\n",
      "prepocess data ...\n",
      "prepocess data ...\n",
      "prepocess data ...\n",
      "prepocess data ...\n",
      "prepocess data ...\n",
      "prepocess data ...\n",
      "prepocess data ...\n",
      "prepocess data ...\n",
      "prepocess data ...\n",
      "prepocess data ...\n",
      "prepocess data ...\n",
      "prepocess data ...\n",
      "prepocess data ...\n",
      "prepocess data ...\n",
      "prepocess data ...\n",
      "prepocess data ...\n",
      "prepocess data ...\n",
      "start compute saliency map\n",
      "Process frame\n",
      "# 0/500\n",
      "(22, 3)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-aca89b7895de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     sm = export_composed_physiological_saliency_map(sessions=sessions,                                                     media=media,                                                     signals=signals,                                                     psyco_construct=psyco_construct,                                                     attribute=attribute,                                                     limit_frame=limit_frame,\n\u001b[0;32m---> 19\u001b[0;31m                                                     destination=\"video\")\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m#data = { \"physm\" : list(sm) }\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-c62b1ae738c3>\u001b[0m in \u001b[0;36mexport_composed_physiological_saliency_map\u001b[0;34m(sessions, media, signals, psyco_construct, attribute, limit_frame, destination)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_physiological_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mpsm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mphysiosm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPhysioSaliencyMap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphysio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgaze\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgaze_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmedia\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmedia\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mphysio_sm_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpsm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_saliency_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlimit_frame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisplay_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mphysio_sm_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphysio_sm_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jovyan/emosm/sm/physiosm.pyc\u001b[0m in \u001b[0;36mcompute_saliency_map\u001b[0;34m(self, limit_frame, display_size)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mframe_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msm_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0;34m\"# {}/{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msm_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mframe_heatmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_frame_saliency_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0;31m# yield frame_heatmap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mframe_heatmap_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_heatmap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jovyan/emosm/sm/basesm.py\u001b[0m in \u001b[0;36mcompute_frame_saliency_map\u001b[0;34m(self, data, display_size, mean_data, normalize)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack"
     ]
    }
   ],
   "source": [
    "##\n",
    "## COMPUTE AND EXPORT INTEGRATED PSYCOPHYSIOLOGICAL SALIENCY MAP FOR GIVEN SESSSION AND GIVEN SIGNALS\n",
    "##\n",
    "\n",
    "all_signals = (\"ECG\", \"EDA\", \"Resp\", \"SKT\")\n",
    "all_psyco_construct = [\"arousal\", \"valence\"]\n",
    "all_attribute = [\"mean\", \"std\"]\n",
    "\n",
    "signal_combination = []\n",
    "for s in map(set,itertools.product(all_signals, repeat=4)):\n",
    "    if s not in signal_combination:\n",
    "        signal_combination.append(s)\n",
    "\n",
    "print sorted(signal_combination, key=len)\n",
    "\n",
    "for signals, psyco_construct, attribute in itertools.product(signal_combination, all_psyco_construct, all_attribute):\n",
    "\n",
    "    sm = export_composed_physiological_saliency_map(sessions=sessions, \\\n",
    "                                                    media=media, \\\n",
    "                                                    signals=signals, \\\n",
    "                                                    psyco_construct=psyco_construct, \\\n",
    "                                                    attribute=attribute, \\\n",
    "                                                    limit_frame=limit_frame,\n",
    "                                                    destination=\"video\")\n",
    "\n",
    "    #data = { \"physm\" : list(sm) }\n",
    "    #signals = \"_\".join(signals)\n",
    "    #filename = config.DATA_EXPORT_DIR_BASE + \"/physm_composed_{}_{}_{}_{}.npz\".format(psyco_construct, attribute, signals, NOW)\n",
    "    #export.toBinaryFile(data=data, filename=filename, compressed=True)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
