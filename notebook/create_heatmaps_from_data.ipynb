{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import io\n",
    "\n",
    "from math import atan2, degrees\n",
    "\n",
    "import imageio\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from scipy.ndimage import gaussian_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(mediafile):\n",
    "    media = imageio.get_reader(\"../Dataset/Mahnob/data/media_24/{}.avi\".format(mediafile))\n",
    "    valence_fixations = pd.DataFrame.from_csv(\"data/valence_data_for_heatmap_creation_{}.csv\".format(mediafile)).applymap(eval)\n",
    "    arousal_fixations = pd.DataFrame.from_csv(\"data/arousal_data_for_heatmap_creation_{}.csv\".format(mediafile)).applymap(eval)\n",
    "    return media, valence_fixations, arousal_fixations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib helper function\n",
    "plt.ioff()\n",
    "\n",
    "dpi = 100\n",
    "DISPLAY_SIZE = (320,200)\n",
    "figsize = (DISPLAY_SIZE[0]/dpi, DISPLAY_SIZE[1]/dpi)\n",
    "extent = [0, DISPLAY_SIZE[0], DISPLAY_SIZE[1], 0]\n",
    "\n",
    "def create_ax():\n",
    "    # determine the figure size in inches\n",
    "    fig = plt.figure(figsize=figsize, frameon=False)\n",
    "    ax = fig.gca()\n",
    "    ax.axis(extent)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    return fig, ax\n",
    "\n",
    "def export(fix, ax):\n",
    "    self.main_axis.imshow(self.base, **self.base_opts)\n",
    "    for overlay, opts in zip(self.overlays, self.overlays_opts):\n",
    "        self.main_axis.imshow(overlay, **opts)\n",
    "    self.main_axis.figure.canvas.draw()\n",
    "    width, height = self.main_figure.get_size_inches() * self.main_figure.get_dpi()\n",
    "    image = np.fromstring(self.main_axis.figure.canvas.tostring_rgb(), dtype='uint8').reshape(int(height), int(width), 3)\n",
    "    return image\n",
    "\n",
    "def fig2data(fig):\n",
    "    \"\"\"\n",
    "    @brief Convert a Matplotlib figure to a 4D numpy array with RGBA channels and return it\n",
    "    @param fig a matplotlib figure\n",
    "    @return a numpy 3D array of RGBA values\n",
    "    \"\"\"\n",
    "    # draw the renderer\n",
    "    fig.canvas.draw()\n",
    "    # Get the RGBA buffer from the figure\n",
    "    w, h = fig.get_size_inches() * fig.get_dpi()\n",
    "    buf = np.fromstring(fig.canvas.tostring_argb(), dtype=np.uint8)\n",
    "    buf.shape = (h, w, 4)\n",
    "    # canvas.tostring_argb give pixmap in ARGB mode. Roll the ALPHA channel to have it in RGBA mode\n",
    "    buf = np.roll(buf, 3, axis=2)\n",
    "    return buf\n",
    "\n",
    "def fig2ImageData(fig, ax):\n",
    "    fig.canvas.draw()\n",
    "    with io.BytesIO() as imgdata:\n",
    "        fig.savefig(imgdata, format='png', dpi=fig.dpi, bbox_inches='tight', transparent=True)\n",
    "        imgdata.seek(0)\n",
    "        im = Image.open(imgdata)\n",
    "        im = np.array(im.getdata())\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function\n",
    " \n",
    "def visual_span_from_distance(distance):\n",
    "    h = 324 # Monitor height in cm\n",
    "    d = distance # Distance between monitor and participant in cm\n",
    "    r = 800 # Vertical resolution of the monitor\n",
    "    size_in_deg = 5. # The stimulus size in pixels\n",
    "    # Calculate the number of degrees that correspond to a single pixel. This will\n",
    "    # generally be a very small value, something like 0.03.\n",
    "    deg_per_px = degrees(atan2(.5*h, d)) / (.5*r)\n",
    "    # Calculate the size of the stimulus in degrees\n",
    "    size_in_px = size_in_deg / deg_per_px\n",
    "    return size_in_px\n",
    "\n",
    "def normalize(data):\n",
    "    return ( data - data.min() ) / ( data.max() - data.min() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_from_fixation(x, y, v, distance=None):\n",
    "    m = np.zeros([DISPLAY_SIZE[1], DISPLAY_SIZE[0]], dtype=float)\n",
    "    m[int(y), int(x)] = v\n",
    "    \n",
    "    if distance is None:\n",
    "        sigma = 12\n",
    "    else:\n",
    "        sigma = 0.17 * visual_span_from_distance(distance) / 4\n",
    "    \n",
    "    m = gaussian_filter(m, sigma=sigma)\n",
    "    return m\n",
    "\n",
    "def compute_frame_saliency_map(data):\n",
    "    ## matrix of zeros\n",
    "    M = np.zeros([DISPLAY_SIZE[1], DISPLAY_SIZE[0]], dtype=float)\n",
    "    # gaussian matrix\n",
    "    for x, y, duration, distance, _ in data:\n",
    "        if 0<=x<=DISPLAY_SIZE[0] and 0<=y<=DISPLAY_SIZE[1]:\n",
    "            m = create_image_from_fixation(x, y, v=duration, distance=distance)\n",
    "            M = np.add(M, m)\n",
    "    return M\n",
    "\n",
    "def compute_frame_emotion_saliency_map(data):\n",
    "    ## matrix of zeros\n",
    "    M = np.zeros([DISPLAY_SIZE[1], DISPLAY_SIZE[0]], dtype=float)\n",
    "    # gaussian matrix\n",
    "    for x, y, duration, distance, feature in data:\n",
    "        if 0<=x<=DISPLAY_SIZE[0] and 0<=y<=DISPLAY_SIZE[1]:\n",
    "            m = create_image_from_fixation(x, y, v=feature, distance=distance)\n",
    "            M = np.add(M, m)\n",
    "    return M\n",
    "\n",
    "def get_frame_saliency_maps(gaze_data, frames, compute_fnc):\n",
    "    frame_saliency_maps = []\n",
    "    \n",
    "    for frame in frames:\n",
    "                \n",
    "        gd = gaze_data.T[frame]\n",
    "        frame_saliency_maps.append(compute_fnc(gd))\n",
    "        \n",
    "    frame_saliency_maps = np.array(frame_saliency_maps)\n",
    "    \n",
    "    # apply normalization to get the information of the relation with other heatmaps\n",
    "    frame_saliency_maps = normalize(frame_saliency_maps)\n",
    "    \n",
    "    # apply some threashold to remove useless peak\n",
    "    #frame_saliency_maps[frame_saliency_maps<=.2] = 0\n",
    "    \n",
    "    return frame_saliency_maps\n",
    "\n",
    "\n",
    "def compute_fixation_scatter(fix):\n",
    "    fig, ax = create_ax()\n",
    "    for f in fix:\n",
    "        x, y, d, distance, _ = f\n",
    "        ax.scatter(x, y, s=2, alpha=.8, c='orange')\n",
    "        r = visual_span_from_distance(distance) / 4\n",
    "        circle = plt.Circle((x, y), 1e-2*d, alpha=.8, color='orange', fill=False)\n",
    "        ax.add_artist(circle)\n",
    "    return fig2ImageData(fig, ax)\n",
    "\n",
    "def get_fixations_scatter(gaze_data, frames):\n",
    "\n",
    "    fixations_scatter = []\n",
    "    for frame in frames:\n",
    "        fix = gaze_data.T[frame]\n",
    "        fixations_scatter.append(compute_fixation_scatter(fix=fix))\n",
    "\n",
    "    fixations_scatter = np.array(fixations_scatter)\n",
    "    \n",
    "    return fixations_scatter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_gaze_heatmap(mediafile):\n",
    "\n",
    "    print(\"Exporting data for mediafile {}\".format(mediafile))\n",
    "    \n",
    "    media, valence_fixations, arousal_fixations = get_data(mediafile)\n",
    "    number_of_frame = media.get_meta_data()['nframes']\n",
    "    \n",
    "    #fixations_scatter  = get_fixations_scatter(fixations, range(number_of_frame))\n",
    "    \n",
    "    fixation_heatmaps = get_frame_saliency_maps(valence_fixations, range(number_of_frame), compute_frame_saliency_map)\n",
    "    np.savez_compressed(\"data/valence_fixation_heatmap_{}.npz\".format(mediafile), heatmaps=fixation_heatmaps)\n",
    "    del fixation_heatmaps\n",
    "    print(\"... valence_fixation_heatmap done.\")\n",
    "    \n",
    "    emotion_heatmaps = get_frame_saliency_maps(valence_fixations, range(number_of_frame), compute_frame_emotion_saliency_map)\n",
    "    np.savez_compressed(\"data/valence_emotion_heatmap_{}.npz\".format(mediafile), heatmaps=emotion_heatmaps)\n",
    "    del emotion_heatmaps\n",
    "    print(\"... valence_emotion_heatmap done.\")\n",
    "    print()\n",
    "    \n",
    "    fixation_heatmaps = get_frame_saliency_maps(arousal_fixations, range(number_of_frame), compute_frame_saliency_map)\n",
    "    np.savez_compressed(\"data/arousal_fixation_heatmap_{}.npz\".format(mediafile), heatmaps=fixation_heatmaps)\n",
    "    del fixation_heatmaps\n",
    "    print(\"... arousal_fixation_heatmap done.\")\n",
    "    \n",
    "    emotion_heatmaps = get_frame_saliency_maps(arousal_fixations, range(number_of_frame), compute_frame_emotion_saliency_map)\n",
    "    np.savez_compressed(\"data/arousal_emotion_heatmap_{}.npz\".format(mediafile), heatmaps=emotion_heatmaps)\n",
    "    del emotion_heatmaps\n",
    "    print(\"... arousal_emotion_heatmap done.\")\n",
    "    print()\n",
    "    \n",
    "    del media\n",
    "    del valence_fixations\n",
    "    del arousal_fixations\n",
    "    \n",
    "    #data = {\n",
    "        #\"fixations_scatter\"  : fixations_scatter,\n",
    "    #    \"fixations_heatmaps\" : fixations_heatmaps,\n",
    "    #    \"emotion_heatmaps\"   : emotion_heatmaps\n",
    "    #}\n",
    "    \n",
    "    #return data-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting data for mediafile 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:4: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... valence_fixation_heatmap done.\n",
      "... valence_emotion_heatmap done.\n",
      "\n",
      "... arousal_fixation_heatmap done.\n",
      "... arousal_emotion_heatmap done.\n",
      "\n",
      "Exporting data for mediafile 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:4: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... valence_fixation_heatmap done.\n",
      "... valence_emotion_heatmap done.\n",
      "\n",
      "... arousal_fixation_heatmap done.\n",
      "... arousal_emotion_heatmap done.\n",
      "\n",
      "Exporting data for mediafile 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:4: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... valence_fixation_heatmap done.\n",
      "... valence_emotion_heatmap done.\n",
      "\n",
      "... arousal_fixation_heatmap done.\n",
      "... arousal_emotion_heatmap done.\n",
      "\n",
      "Exporting data for mediafile 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:4: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... valence_fixation_heatmap done.\n",
      "... valence_emotion_heatmap done.\n",
      "\n",
      "... arousal_fixation_heatmap done.\n",
      "... arousal_emotion_heatmap done.\n",
      "\n",
      "Exporting data for mediafile 111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:4: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... valence_fixation_heatmap done.\n",
      "... valence_emotion_heatmap done.\n",
      "\n",
      "... arousal_fixation_heatmap done.\n",
      "... arousal_emotion_heatmap done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for mediafile in [30, 53, 69, 90, 111]:\n",
    "    data = export_gaze_heatmap(mediafile=mediafile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
