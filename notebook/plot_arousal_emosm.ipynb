{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import imageio\n",
    "\n",
    "from math import atan2, degrees\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from scipy.ndimage import gaussian_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot hetmaps over selected frame without data from rejected sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISPLAY_SIZE = (320,200)\n",
    "extent = [0, DISPLAY_SIZE[0], DISPLAY_SIZE[1], 0]\n",
    "\n",
    "cmap = cm.jet\n",
    "my_cmap = cmap(np.arange(cmap.N))\n",
    "# Set alpha\n",
    "my_cmap[:,-1] = np.linspace(0, 1, cmap.N)\n",
    "# Create new colormap\n",
    "cm_jet = ListedColormap(my_cmap)\n",
    "\n",
    "def visual_span_from_distance(distance, size=5, scale=1):\n",
    "    h = 324 / scale # Monitor height in cm\n",
    "    d = distance / scale # Distance between monitor and participant in cm\n",
    "    r = 800 / scale # Vertical resolution of the monitor\n",
    "    size_in_deg = size # The stimulus size in pixels\n",
    "    # Calculate the number of degrees that correspond to a single pixel. This will\n",
    "    # generally be a very small value, something like 0.03.\n",
    "    deg_per_px = degrees(atan2(.5*h, d)) / (.5*r)\n",
    "    # Calculate the size of the stimulus in degrees\n",
    "    size_in_px = size_in_deg / deg_per_px\n",
    "    return size_in_px\n",
    "\n",
    "\n",
    "def normalize(data):\n",
    "    return ( data - data.min() ) / ( data.max() - data.min() )\n",
    "\n",
    "def get_data(mediafile):\n",
    "    media = imageio.get_reader(\"../Dataset/Mahnob/data/media_24/{}.avi\".format(mediafile))\n",
    "    fixations = pd.DataFrame.from_csv(\"data/arousal_data_for_heatmap_creation_{}.csv\".format(mediafile)).applymap(eval)\n",
    "    fixations_heatmaps = np.load(\"data/arousal_fixation_heatmap_{}.npz\".format(mediafile))['heatmaps']\n",
    "    valence_emotion_heatmaps = np.load(\"data/arousal_emotion_heatmap_{}.npz\".format(mediafile))['heatmaps']\n",
    "\n",
    "    fixations_heatmaps = normalize(fixations_heatmaps)\n",
    "    valence_emotion_heatmaps = normalize(valence_emotion_heatmaps)\n",
    "    \n",
    "    return media, fixations, fixations_heatmaps, valence_emotion_heatmaps\n",
    "\n",
    "def get_media_frame(media, frames):\n",
    "    images = []\n",
    "    for frame in frames:\n",
    "        media.set_image_index(frame-1)\n",
    "        images.append(media.get_next_data())\n",
    "    return images\n",
    "\n",
    "\n",
    "def get_frame_fixations(fix, frames):\n",
    "    frame_fixations = []\n",
    "    for frame in frames:\n",
    "        frame_fixations.append(fix.T[frame-1])\n",
    "    return frame_fixations\n",
    "\n",
    "##\n",
    "## PLOT FUNCTIONS\n",
    "##\n",
    "\n",
    "def create_axes(sub=(1,1)):\n",
    "    \n",
    "    dpi = 100\n",
    "    ncols=sub[0]\n",
    "    nrows=sub[1]\n",
    "    # determine the figure size in inches\n",
    "    figsize = (1280*ncols/dpi, 800*nrows/dpi)\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize, dpi=dpi)\n",
    "    \n",
    "    extent = [0, DISPLAY_SIZE[0], DISPLAY_SIZE[1], 0]\n",
    "\n",
    "    if not isinstance(axes, type(np.array)): \n",
    "        axes = np.array(axes) \n",
    "    \n",
    "    for ax in axes.flatten(): \n",
    "        ax.axis(extent)\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    return fig, axes.flatten()\n",
    "\n",
    "def plot_images(axes, frames):\n",
    "    images = get_media_frame(media, frames)\n",
    "    for ax, im in zip(axes, images):\n",
    "        ax.imshow(im, origin='lower')\n",
    "    \n",
    "def plot_heatmap(axes, data, frames):\n",
    "    for ax, fix in zip(axes, frames):\n",
    "        heatmap = data[frames]\n",
    "        print(heatmap.shape)\n",
    "        ax.imshow(heatmap.squeeze()*5, extent=extent, vmin=0, vmax=5, cmap=cm_jet, alpha=.8)\n",
    "        \n",
    "def plot_fixations(axes, data, frames):\n",
    "    frame_fixations = get_frame_fixations(data, frames)\n",
    "    for ax, fix in zip(axes, frame_fixations):\n",
    "        for f in fix:\n",
    "            x, y, d, distance, _ = f\n",
    "            ax.scatter(x, y, s=1e-2*d, alpha=.8, c='orange')\n",
    "            r = 0.17 * visual_span_from_distance(distance, scale=4)\n",
    "            circle = plt.Circle((x, y), r, alpha=.8, color='orange', fill=False)\n",
    "            ax.add_artist(circle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:29: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e96f818ff718>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmediafile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m53\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmedia\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixation_heatmaps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalence_emotion_heatmaps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmediafile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmedia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_meta_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nframes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-006bb3e38542>\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(mediafile)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mvalence_emotion_heatmaps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/arousal_emotion_heatmap_{}.npz\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmediafile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'heatmaps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mfixations_heatmaps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfixations_heatmaps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mvalence_emotion_heatmaps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalence_emotion_heatmaps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-006bb3e38542>\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmediafile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mediafile = 53\n",
    "media, fixations, fixation_heatmaps, valence_emotion_heatmaps = get_data(mediafile)\n",
    "\n",
    "nframes = media.get_meta_data()['nframes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del fixations, fixation_heatmaps, valence_emotion_heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 200, 320)\n",
      "(1, 200, 320)\n",
      "(1, 200, 320)\n",
      "(1, 200, 320)\n",
      "(1, 200, 320)\n",
      "(1, 200, 320)\n",
      "(1, 200, 320)\n",
      "(1, 200, 320)\n",
      "(1, 200, 320)\n",
      "(1, 200, 320)\n",
      "(1, 200, 320)\n",
      "(1, 200, 320)\n",
      "(1, 200, 320)\n",
      "(1, 200, 320)\n",
      "(1, 200, 320)\n",
      "(1, 200, 320)\n",
      "(1, 200, 320)\n",
      "(1, 200, 320)\n",
      "(1, 200, 320)\n",
      "(1, 200, 320)\n",
      "(1, 200, 320)\n",
      "(1, 200, 320)\n",
      "(1, 200, 320)\n",
      "(1, 200, 320)\n",
      "(1, 200, 320)\n",
      "(1, 200, 320)\n",
      "(1, 200, 320)\n",
      "(1, 200, 320)\n",
      "(1, 200, 320)\n",
      "(1, 200, 320)\n",
      "(1, 200, 320)\n",
      "(1, 200, 320)\n",
      "(1, 200, 320)\n",
      "(1, 200, 320)\n",
      "(1, 200, 320)\n",
      "(1, 200, 320)\n",
      "(1, 200, 320)\n",
      "(1, 200, 320)\n",
      "(1, 200, 320)\n",
      "(1, 200, 320)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/matplotlib/pyplot.py:522: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 200, 320)\n",
      "(1, 200, 320)\n",
      "(1, 200, 320)\n",
      "(1, 200, 320)\n",
      "(1, 200, 320)\n",
      "(1, 200, 320)\n",
      "(1, 200, 320)\n",
      "(1, 200, 320)\n",
      "(1, 200, 320)\n",
      "(1, 200, 320)\n",
      "(1, 200, 320)\n",
      "(1, 200, 320)\n"
     ]
    }
   ],
   "source": [
    "plt.ioff()\n",
    "for frame in range(1, nframes+1, 100): #range(1, nframes+1, 100):\n",
    "    \n",
    "    f = [frame]\n",
    "    fig, axes = create_axes((2,2))\n",
    "    \n",
    "    plot_images([axes[0]], f)\n",
    "    plot_images([axes[1]], f)\n",
    "    plot_images([axes[2]], f)\n",
    "    plot_images([axes[3]], f)\n",
    "\n",
    "    plot_fixations([axes[1]], fixations, f)\n",
    "    plot_heatmap([axes[2]], fixation_heatmaps, f)\n",
    "    plot_heatmap([axes[3]], valence_emotion_heatmaps, f)\n",
    "\n",
    "    for ax, title in zip(axes, ['Frame', 'Fissazioni', 'Heatmap Fissazioni', 'Heatmap Valenza']):\n",
    "        ax.set_title(title, fontdict={'fontsize': 34}, pad=12)\n",
    "    \n",
    "    fig.savefig(\"hm_comparison_aro/{}_{}.png\".format(mediafile, frame), format='png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
